{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Command Line tools\n",
    "\n",
    "> Define some wrappers for command line tools for training the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp cli "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: No IPv4 address found on anpi1 !\n",
      "WARNING: No IPv4 address found on anpi0 !\n",
      "WARNING: more No IPv4 address found on en3 !\n"
     ]
    }
   ],
   "source": [
    "#| export \n",
    "\n",
    "import argparse\n",
    "from mdetect.core import *\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score,  accuracy_score,roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.metrics import RocCurveDisplay, ConfusionMatrixDisplay\n",
    "from sklearn.calibration import CalibrationDisplay\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "import pandas as pd\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "\n",
    "def main_train():\n",
    "    \n",
    "    parser = argparse.ArgumentParser(description='Train a XGBoost model on PCAPs')\n",
    "    parser.add_argument('--malware', type=str, default='data', help='Path to directory containing malware PCAPs')\n",
    "    parser.add_argument('--benign', type=str, default='data', help='Path to directory containing benign PCAPs')\n",
    "    parser.add_argument('--save', type=str, default='inference.pkl', help='Path to save the model')\n",
    "    parser.add_argument('--seed', type=int, default=42, help='Random seed')\n",
    "    parser.add_argument('--test_size', type=float, default=0.3, help='Test split size')\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    benign = Path(args.benign)\n",
    "    malware = Path(args.malware)\n",
    "    \n",
    "    benign_files = list(benign.glob('*.pcap*'))\n",
    "    malware_files = list(malware.glob('*.pcap*'))\n",
    "    \n",
    "    print(f\"Found {len(benign_files)} benign files and {len(malware_files)} malware files\")\n",
    "    \n",
    "    print(\"Processing PCAP files...\")\n",
    "    Xm = pd.concat([collect_flow_stats(f) for f in malware_files])\n",
    "    Xb = pd.concat([collect_flow_stats(f) for f in benign_files])\n",
    "    X = pd.concat([Xm, Xb])\n",
    "    y = np.array([1] * Xm.shape[0] + [0] * Xb.shape[0])\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = args.test_size, random_state=args.seed)\n",
    "    \n",
    "    # Show the sizes of the training and test sets\n",
    "    print(\"Training set has {} samples.\".format(X_train.shape[0]))\n",
    "    print(\"Test set has {} samples.\".format(X_test.shape[0]))\n",
    "\n",
    "    # Show the balance of labels in the training and test sets\n",
    "    print(\"Training set has {} malware samples.\".format(sum(y_train)))\n",
    "    print(\"Training set has {} legitimate samples.\".format(len(y_train) - sum(y_train)))\n",
    "    \n",
    "    baseline_pipe = [('scale', ColumnTransformer([('scaler', StandardScaler(), slice(0, 20))], remainder='passthrough'))]\n",
    "    xgb_pipe = Pipeline(baseline_pipe + [('model', xgb.XGBClassifier(random_state=args.seed, eval_metric='logloss'))])\n",
    "    modelcand = ModelCandidate(xgb_pipe, 'RandomForest')\n",
    "    fit_model = evaluate(modelcand, X_train, y_train, X_test, y_test)\n",
    "    \n",
    "    # print all the model metrics\n",
    "    print(f\"Accuracy: {fit_model.accuracy_score}\")\n",
    "    print(f\"Confusion Matrix: {fit_model.confusion_matrix}\")\n",
    "    print(f\"F1 Score: {fit_model.f1_score}\")\n",
    "    print(f\"AUC: {fit_model.auc_score}\")\n",
    "    print(f\"Cross validation score: {fit_model.cv_scores}\")\n",
    "    \n",
    "    # Save the model \n",
    "    pipeline_filename = args.save\n",
    "    joblib.dump(fit_model.modelcand.model, pipeline_filename)\n",
    "    \n",
    "    print(f\"Model saved to {pipeline_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "\n",
    "def main_transform():\n",
    "    \n",
    "    parser = argparse.ArgumentParser(description='Transform pcap files to features')\n",
    "    parser.add_argument('--malware', type=str, default='data', help='path to malware pcap files')\n",
    "    parser.add_argument('--benign', type=str, default='data', help='path to benign pcap files')\n",
    "    parser.add_argument('--save', type=str, default=\".\", help='save the features to disk at this path')\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    X, y = load_training_validation(Path(args.malware), \n",
    "                                    Path(args.benign), \n",
    "                                    save=True, \n",
    "                                    load=False,\n",
    "                                    store_path=Path(args.save))\n",
    "    print(f\"Features saved to {args.save}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def main_predict():\n",
    "    \n",
    "    parser = argparse.ArgumentParser(description='Predict if a pcap file is malware or benign, reports the number of malware flows detected')\n",
    "    parser.add_argument('--data', type=str, default='data', help='path to pcap file')\n",
    "    parser.add_argument('--model', type=str, help='path to model in pickle format, e.g. inference.pkl from the malware-train script')\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    pipeline = joblib.load(args.model) # pretrained model\n",
    "    Xt = pd.concat([collect_flow_stats(f) for f in [Path(args.data)]], axis=0)\n",
    "    y_pred = pipeline.predict(Xt)\n",
    "    \n",
    "    print(f\"Prediction: {y_pred.sum()} malware flows detected out of {len(y_pred)} flows\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
