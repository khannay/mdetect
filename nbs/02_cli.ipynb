{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Command Line tools\n",
    "\n",
    "> Define some wrappers for command line tools for training the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp cli "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "\n",
    "import argparse\n",
    "from mdetect.core import *\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score,  accuracy_score,roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.metrics import RocCurveDisplay, ConfusionMatrixDisplay\n",
    "from sklearn.calibration import CalibrationDisplay\n",
    "from sklearn.manifold import TSNE\n",
    "from imblearn.over_sampling import SMOTENC \n",
    "from imblearn.pipeline import Pipeline as imbPipeline\n",
    "\n",
    "import pandas as pd\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "\n",
    "def main_train():\n",
    "    \n",
    "    parser = argparse.ArgumentParser(description='Train a model')\n",
    "    parser.add_argument('--data', type=str, default='data', help='data directory')\n",
    "    parser.add_argument('--save', type=str, default='inference.pkl', help='Path to save the model')\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    \n",
    "    # Get the filename of the file that starts with X_* in the data directory\n",
    "    features = glob.glob(f'{args.data}/X*')[0]\n",
    "    labels = glob.glob(f'{args.data}/y*')[0]\n",
    "    \n",
    "    if len(features) == 0 or len(labels) == 0:\n",
    "        raise Exception(\"No data found\")\n",
    "    if len(features) > 1 or len(labels) > 1:\n",
    "        raise Exception(f\"Multiple data files found {features} {labels}\")\n",
    "    \n",
    "    X = pd.read_csv(features[0], delimiter=',')\n",
    "    y = pd.read_csv(labels, delimiter=',').to_numpy() \n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=42)\n",
    "    \n",
    "    rf_pipe = imbPipeline([('resample', SMOTENC(categorical_features=[8,9,10])), \n",
    "                       ('model', RandomForestClassifier(n_estimators = 30, random_state=42)),\n",
    "                       ])\n",
    "    modelcand = ModelCandidate(rf_pipe, 'RandomForest')\n",
    "    fit_model = evaluate(modelcand, X_train, y_train, X_test, y_test)\n",
    "    # print all the model metrics\n",
    "    print(f\"Accuracy: {fit_model.accuracy_score}\")\n",
    "    print(f\"Confusion Matrix: {fit_model.confusion_matrix}\")\n",
    "    print(f\"F1 Score: {fit_model.f1_score}\")\n",
    "    print(f\"AUC: {fit_model.auc_score}\")\n",
    "    print(f\"Cross validation score: {fit_model.cv_scores}\")\n",
    "    \n",
    "    # Save the model \n",
    "    pipeline_filename = args.save\n",
    "    joblib.dump(fit_model.modelcand, pipeline_filename)\n",
    "    \n",
    "    print(f\"Model saved to {pipeline_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "\n",
    "def main_transform():\n",
    "    \n",
    "    parser = argparse.ArgumentParser(description='Transform pcap files to features')\n",
    "    parser.add_argument('--malware -md', type=str, default='data', help='path to malware pcap files')\n",
    "    parser.add_argument('--benign -bd', type=str, default='data', help='path to benign pcap files')\n",
    "    parser.add_argument('--save -s', type=str, default=\".\", help='save the features to disk at this path')\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    X, y = load_training_validation(Path(args.malware), Path(args.benign), save=False, load=False)\n",
    "    \n",
    "    savepath = Path(args.save)\n",
    "    benign_filehash = hash_datafiles(benign_files)\n",
    "    malware_filehash = hash_datafiles(malware_files)\n",
    "    \n",
    "    X_filename = f'X_{benign_filehash}_{malware_filehash}.csv.gz'\n",
    "    y_filename = f'y_{benign_filehash}_{malware_filehash}.csv.gz'\n",
    "    \n",
    "    X.to_csv(savepath / X_filename, index=False)\n",
    "    pd.DataFrame(y).to_csv(savepath / y_filename, index=False)\n",
    "    \n",
    "    print(f\"Saved X to {savepath / X_filename}\")\n",
    "    print(f\"Saved y to {savepath / y_filename}\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_predict():\n",
    "    \n",
    "    parser = argparse.ArgumentParser(description='Predict if a pcap file is malware or benign')\n",
    "    parser.add_argument('--data -d', type=str, default='data', help='path to pcap file')\n",
    "    parser.add_argument('--model -m', type=str, help='path to model in pickle format')\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "    pipeline = joblib.load(args.model)\n",
    "    X = collect_flow_stats(args.data)\n",
    "    y_pred = pipeline.predict(args.data)\n",
    "    \n",
    "    print(f\"Prediction: {y_pred.sum} malware flows detected out of {len(y_pred)} flows\")\n",
    "    print(\"Give a probability of the pcap containing malware\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
